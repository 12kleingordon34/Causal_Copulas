---
title: "Comparison Against Didelez Example"
author: "Dan Manela"
date: "23/01/2022"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Comparison of Methods}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  echo = TRUE,
  comment = "#>",
  cache = FALSE,
  fig.width=7, 
  fig.height=7
)
# knitr::knit_theme$set("earendel")
```

As always, we begin by loading the package.

```{r load, include=TRUE, message=FALSE}
library(tidyverse)
library(purrr)
library(causl)
library(survey)
```

## Load Data

We first select the variables in our model, choosing the ones mentioned in the running example of Evans and Didelez (2021). In this case the model is given by the graph $A_0 \rightarrow L \rightarrow A_1 \rightarrow Y$ with $A_0 \rightarrow A_1$ and $L \leftrightarrow Y$.

```{r}
didelez_data <- suppressMessages(read_csv('validation_datasets/didelez_simulation.csv'))
```

We next define the parameters for our model, again following Evans and Didelez (2021).

```{r params}
pars <- list(A0 = list(beta = 0),
             L = list(beta = c(0.3,-0.2), phi=1),
             A1 = list(beta = c(-0.3,0.4,0.3,0)), 
             Y = list(beta = c(-0.5,0.2,0.3,0), phi=1),
             cop = list(beta = c(1,0.5)))
```

We can check that the distribution actually has the correct form for the first three variables ($A_0, L, A_1$):

```{r glms1, echo=-1}
options(digits=4)
summary(glm(A ~ 1, family=binomial, data=didelez_data))$coef
summary(glm(L ~ A, family=Gamma(link="log"), data=didelez_data))$coef
glmB <- glm(B ~ A*L, family=binomial, data=didelez_data)
summary(glmB)$coef
```

Indeed, all the parameters are close to their correct values.

We can also use inverse probability weighting to check the causal relationship for $Y$.

```{r chk}
ps <- fitted(glmB)
wt <- didelez_data$B/ps + (1-didelez_data$B)/(1-ps)
summary(svyglm(Y ~ A*B, design = svydesign(~1, weights=~wt, data = didelez_data)))$coef
```

### Outcome Regression

We start with a naive outcome regression approach, where we fit a linear model for $Y$ regressed on various combinations of $A_0,A_1$ and $L$. As we can see, none yield the parameters that interest us.

```{r outcome}
lmY_AB <- lm(Y ~ A*B, data=didelez_data)
lmY_AB_L <- lm(Y ~ A*B + L, data=didelez_data)
lmY_ABL <- lm(Y ~ A*B*L, data=didelez_data)
summary(lmY_AB)$coef
summary(lmY_AB_L)$coef
summary(lmY_ABL)$coef
```

```{r tab_or, echo=FALSE}
tab_or <- summary(lmY_AB)$coef[,1:2]
tab_or <- cbind(tab_or, tab_or[,1] - pars$Y$beta)
colnames(tab_or) <- c("Est.", "SE", "Bias")
```

### Inverse Propensity Weighting

We can try the rather more principled approach of using inverse propensity score weighting, and this time the estimates are unbiased.

```{r ipw}
## get the weights from model for B
glmB <- glm(B ~ A*L, family=binomial, data=didelez_data)
ps <- fitted(glmB)
wt <- didelez_data$B/ps + (1-didelez_data$B)/(1-ps) 

lmY_AB_w <- svyglm(Y ~ A*B, design = svydesign(id=~1, data=didelez_data, weights = ~wt))
summary(lmY_AB_w)$coef
```

Notice that the coefficients are now correct.

```{r tab_ipw, echo=FALSE}
tab_ipw <- summary(lmY_AB_w)$coef[,1:2]
tab_ipw <- cbind(tab_ipw, tab_ipw[,1] - pars$Y$beta)
colnames(tab_ipw) <- c("Est.", "SE", "Bias")
```

### Doubly Robust Approach

We can also use an approach based on doubly-robust estimating equations.

```{r, echo=FALSE, eval=FALSE}
glmY <- lm(Y ~ A*B*I(log(L)), data=didelez_data)
glmA <- glm(A ~ 1, data=didelez_data, family=binomial)
dat0 <- dat1 <- dat00 <- dat10 <- dat01 <- dat11 <- didelez_data
dat0$B = 0
dat1$B = 1
dat00[,c("A", "B")] = 0
dat10 = dat10 %>% mutate(A=1, B=0)
dat01 = dat01 %>% mutate(A=0, B=1)
dat11 = dat11 %>% mutate(A=1, B=1)

## weights
w1 <- fitted(glmB)
w1[didelez_data$B==0] <- 1 - w1[didelez_data$B==0]
w0 <- rep(1, nrow(didelez_data))
# w0 <- predict(glmA, dat, "response")
# w0[dat$A==0] <- 1 - w0[dat$A==0]
w <- w0 * w1

q <- predict(glmY, didelez_data)
q0 <- predict(glmY, dat0)
q1 <- predict(glmY, dat1)
q00 <- predict(glmY, dat00)
q01 <- predict(glmY, dat01)
q10 <- predict(glmY, dat10)
q11 <- predict(glmY, dat11)

## predict outcomes
wts1 <- (didelez_data$Y - q)*didelez_data$B/w + q1
# mean(wts1)
# sd(wts1)/sqrt(nrow(dat))

wts0 <- (didelez_data$Y - q)*(1-didelez_data$B)/w + q0
# mean(wts0)
# sd(wts0)/sqrt(nrow(dat))

# mean(wts1 - wts0)
# sd(wts1 - wts0)/sqrt(nrow(dat))

# wts11 <- (dat$Y - q)*dat$B*dat$A/w + q11
# wts10 <- (dat$Y - q)*(1-dat$B)*dat$A/w + q10
# wts01 <- (dat$Y - q)*dat$B*(1-dat$A)/w + q01
# wts00 <- (dat$Y - q)*(1-dat$B)*(1-dat$A)/w + q00
# 
# tab_dr <- cbind(c(mean(wts00), mean(wts10 - wts00), mean(wts01 - wts00), mean(wts11 - wts01 - wts10 + wts00)), 
#                 c(sd(wts00),
#                   sd(wts10 - wts00), 
#                   sd(wts01 - wts00), 
#                   sd(wts11 - wts01 - wts10 + wts00))/sqrt(nrow(dat)))
# tab_dr <- cbind(tab_dr, tab_dr[,1] - pars$Y$beta)
# colnames(tab_dr) <- c("Est.", "SE", "Bias")
```

```{r dr, eval=TRUE}
## get datasets with different values of B
dat0 <- dat1 <- didelez_data
dat0$B <- 0
dat1$B <- 1

## get outcome models
glmY <- lm(Y ~ B*I(log(L)), data=didelez_data)
q <- predict(glmY, didelez_data)
q0 <- predict(glmY, dat0)
q1 <- predict(glmY, dat1)

n0 <- sum(didelez_data$A == 0)
n1 <- sum(didelez_data$A == 1)

## weights
w1 <- fitted(glmB)
w1[didelez_data$B==0] <- 1 - w1[didelez_data$B==0]
w0 <- rep(1, nrow(didelez_data))
# w0 <- predict(glmA, dat, "response")
# w0[dat$A==0] <- 1 - w0[dat$A==0]
w <- w0 * w1


## obtain E[Y | do(A=A,B=B)] for each (A,B)
wts01 <- ((didelez_data$Y - q)*didelez_data$B/w + q1)[didelez_data$A == 0]
wts00 <- ((didelez_data$Y - q)*(1-didelez_data$B)/w + q0)[didelez_data$A == 0]
wts11 <- ((didelez_data$Y - q)*didelez_data$B/w + q1)[didelez_data$A == 1]
wts10 <- ((didelez_data$Y - q)*(1-didelez_data$B)/w + q0)[didelez_data$A == 1]
se00 <- sd(wts00)/sqrt(n0)
se10 <- sd(wts10)/sqrt(n1)
se01 <- sd(wts01)/sqrt(n0)
se11 <- sd(wts11)/sqrt(n1)

cse00_01 <- mean((wts00 - mean(wts00))*(wts01 - mean(wts01)))/n0
cse10_11 <- mean((wts10 - mean(wts10))*(wts11 - mean(wts11)))/n1

## use these to obtain estimates, standard errors and bias
est <- c(mean(wts00), mean(wts10) - mean(wts00), mean(wts01 - wts00), mean(wts11 - wts10) - mean(wts01 - wts00))
se <- c(se00, 
        sqrt(se10^2 - 2*cse00_01 + se00^2), 
        sqrt(se01^2 + se00^2),
        sqrt(se10^2 - 2*cse00_01 + se00^2) + sqrt(se10^2 - 2*cse10_11 + se11^2))
tab_dr <- cbind(est, se)
rownames(tab_dr) <- rownames(tab_ipw)
tab_dr
```

```{r tab_dr}
bias <- est - pars$Y$beta
tab_dr <- cbind(est, se, bias)
colnames(tab_dr) <- c("Est.", "SE", "Bias")
```

### Maximum Likelihood

Finally, we can fit using our own code with the black-box optimizer, and since we are fitting the correct model it is guaranteed to be consistent and asymptotically efficient.

We use 1000 samples for this exercise due to time limitations.

```{r mle, cache=FALSE, time_it = TRUE}
dat <- didelez_data[1:1000, ]
modY <- fitCausal(as.data.frame(dat), formulas = list(Y ~ A*B, L ~ A, ~ A*B),
                  family = c(1,3,1), control=list(maxit=2e4, newton=TRUE))
modY
```

```{r tab_mle, echo=FALSE, cache=TRUE}
tab_mle <- cbind(modY$pars$Y$beta[1:4], modY$pars$Y$beta_se[1:4], 
                 modY$pars$Y$beta[1:4]-pars$Y$beta)
colnames(tab_mle) <- c("Est.", "SE", "Bias")
tab_mle
```

### Comparison of Results

Outcome regression fails miserably, but this is to be expected because the model is hopelessly misspecified. IP weighting, double robust estimates and the MLE all appear to be correct.

```{r results, echo=FALSE, results="asis"}
results <- cbind(tab_or, tab_ipw, tab_dr, tab_mle)
results[,1+rep(0:3, each=1)*3] <- round(results[,1+rep(0:3, each=1)*3], 2)
results[,2+rep(0:3, each=1)*3] <- round(results[,2+rep(0:3, each=1)*3], 3)
results[,3+(0:3)*3] <- round(results[,3+(0:3)*3], 3)
results[,ncol(results)] <- round(results[,ncol(results)], 3)
kableExtra::kbl(results, booktabs=TRUE) %>%
  kableExtra::add_header_above(c(" ","Outcome Regression"=3,"IP Weighting"=3,"Double Robust"=3,"MLE"=3))
# xtable::xtable(results, digits=c(0,rep(c(2,3,3),4)), align="|r|rrr|rrr|rrr|")
```
